# asl-interpreter !!
welcome to my asl interpreter project! I wanted to learn more about machine learning and see if I could demystify the concepts behind deep learning and neural networks for myself. This project uses OpenCV to recognize the user's hand and uses Tensorflow and Keras for the neural network. Furthermore, I was able to use matplotlib to visualize the data as I worked on this project-- very helpful!

## why ?
Why did I decide on making an ASL-interpreter?
I have always been passionate about making an impact on peoples' lives, especially through a healthcare and accesibililty lens. Being able to maniplulate technology to enhance people's lives has been the latest focus of mine, combining both my passion for healthcare and technology as well as my personal goals. 
This project was the first time I was able to explore neural networks and deep learning. Although I have taken online courses surrounding the concepts of these topics, I never experimented with the code myself. I plan for this project to be the first of many machine learning and data science based projects!

## build status
Currently working on a webpage to fully deploy the model. Also learning more about model serving.

## tools
Languages used for this project: Python, HTML/CSS, Javascript

## credits
You can find the data set used for this model here: https://www.kaggle.com/datasets/grassknoted/asl-alphabet
Thank you to TDS for providing helpful information on concepts behind the model, and data-flair for information on using OpenCV. 

